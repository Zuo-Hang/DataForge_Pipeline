## DataForge Pipeline

DataForge Pipeline 旨在通过一个简化版 “Hive + ETL + 指标体系” 案例，串联数据采集、清洗、入仓和指标展示的端到端流程。该仓库将作为练习与面试展示用项目，逐步扩展出调度、监控、回溯等能力。

### 当前 MVP 目标
- 使用 Pandas 编写本地 ETL（清洗 + 加工）
- 以 Hive 作为仓库，完成建表、分区管理与数据加载
- 构建 `DAU`、订单量等基础指标的 SQL
- 用脚本运行 ETL + 查询，并输出指标结果

### 目录结构
```
├── config/                 # 连接配置与常量
├── data_sources/           # 原始与清洗后的样例数据
├── docs/                   # 数据流与指标文档
├── etl/                    # 清洗、解析、加载脚本
├── hive/                   # Hive 建表与指标 SQL
├── jobs/                   # 任务编排脚本与后续调度入口
└── README.md
```

### 下一步计划
1. 准备模拟用户与订单数据
2. 完成 Pandas 清洗脚本，生成中间文件
3. 编写 Hive 建表与指标 SQL，并对接加载脚本
4. 补充文档，说明数据流、字段定义与指标口径

